; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 5
; RUN: llc < %s | FileCheck %s

target triple = "aarch64"

define void @reproducer(ptr %ptr, ptr %ptr2, <8 x i32> %vec.arg) {
; CHECK-LABEL: reproducer:
; CHECK:       // %bb.0: // %entry
; CHECK-NEXT:    sub sp, sp, #112
; CHECK-NEXT:    stp x29, x30, [sp, #80] // 16-byte Folded Spill
; CHECK-NEXT:    stp x20, x19, [sp, #96] // 16-byte Folded Spill
; CHECK-NEXT:    .cfi_def_cfa_offset 112
; CHECK-NEXT:    .cfi_offset w19, -8
; CHECK-NEXT:    .cfi_offset w20, -16
; CHECK-NEXT:    .cfi_offset w30, -24
; CHECK-NEXT:    .cfi_offset w29, -32
; CHECK-NEXT:    mov x8, xzr
; CHECK-NEXT:    stp q0, q1, [sp, #16] // 32-byte Folded Spill
; CHECK-NEXT:    mov x19, x1
; CHECK-NEXT:    ld2 { v0.4s, v1.4s }, [x8]
; CHECK-NEXT:    add x8, sp, #48
; CHECK-NEXT:    mov x20, x0
; CHECK-NEXT:    st1 { v0.2d, v1.2d }, [x8] // 32-byte Folded Spill
; CHECK-NEXT:    bl bar
; CHECK-NEXT:    ldp q1, q0, [sp, #16] // 32-byte Folded Reload
; CHECK-NEXT:    mov w8, #1 // =0x1
; CHECK-NEXT:    uzp2 v0.4s, v1.4s, v0.4s
; CHECK-NEXT:    dup v1.2d, x8
; CHECK-NEXT:    add x8, sp, #48
; CHECK-NEXT:    ld1 { v5.2d, v6.2d }, [x8] // 32-byte Folded Reload
; CHECK-NEXT:    ushll2 v2.2d, v6.4s, #1
; CHECK-NEXT:    ushll v3.2d, v6.2s, #1
; CHECK-NEXT:    ushll v4.2d, v5.2s, #0
; CHECK-NEXT:    mov v6.16b, v5.16b
; CHECK-NEXT:    ushll2 v5.2d, v0.4s, #1
; CHECK-NEXT:    ushll v0.2d, v0.2s, #1
; CHECK-NEXT:    orr v3.16b, v3.16b, v4.16b
; CHECK-NEXT:    ushll2 v6.2d, v6.4s, #0
; CHECK-NEXT:    orr v0.16b, v0.16b, v1.16b
; CHECK-NEXT:    orr v2.16b, v2.16b, v6.16b
; CHECK-NEXT:    stp q0, q3, [sp, #32] // 32-byte Folded Spill
; CHECK-NEXT:    orr v0.16b, v5.16b, v1.16b
; CHECK-NEXT:    stp q0, q2, [sp] // 32-byte Folded Spill
; CHECK-NEXT:    bl bar
; CHECK-NEXT:    ldr q1, [sp, #16] // 16-byte Folded Reload
; CHECK-NEXT:    ldr q0, [sp, #48] // 16-byte Folded Reload
; CHECK-NEXT:    ldp x29, x30, [sp, #80] // 16-byte Folded Reload
; CHECK-NEXT:    stp q0, q1, [x20]
; CHECK-NEXT:    ldr q1, [sp] // 16-byte Folded Reload
; CHECK-NEXT:    ldr q0, [sp, #32] // 16-byte Folded Reload
; CHECK-NEXT:    stp q0, q1, [x19]
; CHECK-NEXT:    ldp x20, x19, [sp, #96] // 16-byte Folded Reload
; CHECK-NEXT:    add sp, sp, #112
; CHECK-NEXT:    ret
entry:
  %wide.vec = load <8 x i32>, ptr null, align 4
  call void @bar()
  %strided.vec = shufflevector <8 x i32> %wide.vec, <8 x i32> poison, <4 x i32> <i32 0, i32 2, i32 4, i32 6>
  %strided.vec2 = shufflevector <8 x i32> %wide.vec, <8 x i32> poison, <4 x i32> <i32 1, i32 3, i32 5, i32 7>
  %strided.vec3 = shufflevector <8 x i32> %vec.arg, <8 x i32> poison, <4 x i32> <i32 1, i32 3, i32 5, i32 7>
  %1 = zext <4 x i32> %strided.vec2 to <4 x i64>
  %2 = zext <4 x i32> %strided.vec3 to <4 x i64>
  %3 = shl <4 x i64> %1, <i64 1, i64 1, i64 1, i64 1>
  %4 = shl <4 x i64> %2, <i64 1, i64 1, i64 1, i64 1>
  %5 = zext <4 x i32> %strided.vec to <4 x i64>
  %6 = or <4 x i64> %3, %5
  %7 = or <4 x i64> %4, <i64 1, i64 1, i64 1, i64 1>
  call void @bar()
  store <4 x i64> %6, ptr %ptr, align 8
  store <4 x i64> %7, ptr %ptr2, align 8
  ret void
}

declare void @bar()

