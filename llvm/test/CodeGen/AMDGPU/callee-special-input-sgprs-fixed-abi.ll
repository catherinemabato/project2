; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 5
; RUN: opt -passes=amdgpu-attributor -mcpu=kaveri < %s | llc -enable-ipra=0 | FileCheck -enable-var-scope -check-prefixes=GCN,CIVI %s
; RUN: opt -passes=amdgpu-attributor -mcpu=gfx900 < %s | llc -enable-ipra=0 | FileCheck -enable-var-scope -check-prefixes=GCN,GFX9 %s

target triple = "amdgcn-amd-amdhsa"

; GCN-LABEL: {{^}}use_dispatch_ptr:
; GCN: s_load_dword s{{[0-9]+}}, s[4:5]
define hidden void @use_dispatch_ptr() #1 {
; GCN-LABEL: use_dispatch_ptr:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    s_load_dword s4, s[4:5], 0x0
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %dispatch_ptr = call noalias ptr addrspace(4) @llvm.amdgcn.dispatch.ptr() #0
  %value = load volatile i32, ptr addrspace(4) %dispatch_ptr
  ret void
}

; GCN-LABEL: {{^}}kern_indirect_use_dispatch_ptr:
; GCN-NOT: s[4:5]
; GCN-NOT: s4
; GCN-NOT: s5
; GCN: .amdhsa_user_sgpr_dispatch_ptr 1
define amdgpu_kernel void @kern_indirect_use_dispatch_ptr(i32) #1 {
; CIVI-LABEL: kern_indirect_use_dispatch_ptr:
; CIVI:       ; %bb.0:
; CIVI-NEXT:    s_add_i32 s8, s8, s11
; CIVI-NEXT:    s_lshr_b32 flat_scratch_hi, s8, 8
; CIVI-NEXT:    s_add_u32 s0, s0, s11
; CIVI-NEXT:    s_addc_u32 s1, s1, 0
; CIVI-NEXT:    s_mov_b32 s32, 0
; CIVI-NEXT:    s_mov_b32 flat_scratch_lo, s9
; CIVI-NEXT:    s_getpc_b64 s[6:7]
; CIVI-NEXT:    s_add_u32 s6, s6, use_dispatch_ptr@rel32@lo+4
; CIVI-NEXT:    s_addc_u32 s7, s7, use_dispatch_ptr@rel32@hi+12
; CIVI-NEXT:    s_swappc_b64 s[30:31], s[6:7]
; CIVI-NEXT:    s_endpgm
;
; GFX9-LABEL: kern_indirect_use_dispatch_ptr:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_add_u32 flat_scratch_lo, s8, s11
; GFX9-NEXT:    s_addc_u32 flat_scratch_hi, s9, 0
; GFX9-NEXT:    s_add_u32 s0, s0, s11
; GFX9-NEXT:    s_addc_u32 s1, s1, 0
; GFX9-NEXT:    s_mov_b32 s32, 0
; GFX9-NEXT:    s_getpc_b64 s[6:7]
; GFX9-NEXT:    s_add_u32 s6, s6, use_dispatch_ptr@rel32@lo+4
; GFX9-NEXT:    s_addc_u32 s7, s7, use_dispatch_ptr@rel32@hi+12
; GFX9-NEXT:    s_swappc_b64 s[30:31], s[6:7]
; GFX9-NEXT:    s_endpgm
  call void @use_dispatch_ptr()
  ret void
}

; GCN-LABEL: {{^}}use_queue_ptr:
; GCN: s_mov_b64 s[4:5], 0xc8
; GCN-NEXT: s_load_dwordx2 s[4:5], s[4:5], 0x0
define hidden void @use_queue_ptr() #1 {
; GCN-LABEL: use_queue_ptr:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    s_load_dword s4, s[6:7], 0x0
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %queue_ptr = call noalias ptr addrspace(4) @llvm.amdgcn.queue.ptr() #0
  %value = load volatile i32, ptr addrspace(4) %queue_ptr
  ret void
}

; GCN-LABEL: {{^}}kern_indirect_use_queue_ptr:
; GCN: s_swappc_b64 s[30:31], s[4:5]
; GCN: .amdhsa_user_sgpr_queue_ptr 0
define amdgpu_kernel void @kern_indirect_use_queue_ptr(i32) #1 {
; CIVI-LABEL: kern_indirect_use_queue_ptr:
; CIVI:       ; %bb.0:
; CIVI-NEXT:    s_add_i32 s8, s8, s11
; CIVI-NEXT:    s_lshr_b32 flat_scratch_hi, s8, 8
; CIVI-NEXT:    s_add_u32 s0, s0, s11
; CIVI-NEXT:    s_addc_u32 s1, s1, 0
; CIVI-NEXT:    s_add_u32 s8, s6, 8
; CIVI-NEXT:    s_mov_b32 flat_scratch_lo, s9
; CIVI-NEXT:    s_addc_u32 s9, s7, 0
; CIVI-NEXT:    s_mov_b64 s[6:7], s[4:5]
; CIVI-NEXT:    s_mov_b32 s32, 0
; CIVI-NEXT:    s_getpc_b64 s[10:11]
; CIVI-NEXT:    s_add_u32 s10, s10, use_queue_ptr@rel32@lo+4
; CIVI-NEXT:    s_addc_u32 s11, s11, use_queue_ptr@rel32@hi+12
; CIVI-NEXT:    s_swappc_b64 s[30:31], s[10:11]
; CIVI-NEXT:    s_endpgm
;
; GFX9-LABEL: kern_indirect_use_queue_ptr:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_add_u32 flat_scratch_lo, s8, s11
; GFX9-NEXT:    s_addc_u32 flat_scratch_hi, s9, 0
; GFX9-NEXT:    s_add_u32 s0, s0, s11
; GFX9-NEXT:    s_addc_u32 s1, s1, 0
; GFX9-NEXT:    s_add_u32 s8, s6, 8
; GFX9-NEXT:    s_addc_u32 s9, s7, 0
; GFX9-NEXT:    s_mov_b64 s[6:7], s[4:5]
; GFX9-NEXT:    s_mov_b32 s32, 0
; GFX9-NEXT:    s_getpc_b64 s[10:11]
; GFX9-NEXT:    s_add_u32 s10, s10, use_queue_ptr@rel32@lo+4
; GFX9-NEXT:    s_addc_u32 s11, s11, use_queue_ptr@rel32@hi+12
; GFX9-NEXT:    s_swappc_b64 s[30:31], s[10:11]
; GFX9-NEXT:    s_endpgm
  call void @use_queue_ptr()
  ret void
}

; GCN-LABEL: {{^}}use_queue_ptr_addrspacecast:
; GCN: v_mov_b32_e32 v[[LO:[0-9]+]], 0
; GCN-DAG: ds_write_b32 v[[LO]], v[[LO]] offset:16

define hidden void @use_queue_ptr_addrspacecast() #1 {
; CIVI-LABEL: use_queue_ptr_addrspacecast:
; CIVI:       ; %bb.0:
; CIVI-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CIVI-NEXT:    v_mov_b32_e32 v0, 0
; CIVI-NEXT:    s_mov_b32 m0, -1
; CIVI-NEXT:    ds_write_b32 v0, v0 offset:16
; CIVI-NEXT:    s_waitcnt lgkmcnt(0)
; CIVI-NEXT:    s_setpc_b64 s[30:31]
;
; GFX9-LABEL: use_queue_ptr_addrspacecast:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GFX9-NEXT:    v_mov_b32_e32 v0, 0
; GFX9-NEXT:    ds_write_b32 v0, v0 offset:16
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    s_setpc_b64 s[30:31]
  %asc = addrspacecast ptr addrspace(3) inttoptr (i32 16 to ptr addrspace(3)) to ptr
  store volatile i32 0, ptr %asc
  ret void
}

; GCN-LABEL: {{^}}kern_indirect_use_queue_ptr_addrspacecast:
; CIVI: s_swappc_b64 s[30:31], s[4:5]
; CIVI: .amdhsa_user_sgpr_queue_ptr 0

; GFX9-NOT: s_mov_b64 s[6:7]
; GFX9: .amdhsa_user_sgpr_queue_ptr 0
define amdgpu_kernel void @kern_indirect_use_queue_ptr_addrspacecast(i32) #1 {
; CIVI-LABEL: kern_indirect_use_queue_ptr_addrspacecast:
; CIVI:       ; %bb.0:
; CIVI-NEXT:    s_add_i32 s6, s6, s9
; CIVI-NEXT:    s_lshr_b32 flat_scratch_hi, s6, 8
; CIVI-NEXT:    s_add_u32 s0, s0, s9
; CIVI-NEXT:    s_addc_u32 s1, s1, 0
; CIVI-NEXT:    s_add_u32 s8, s4, 8
; CIVI-NEXT:    s_addc_u32 s9, s5, 0
; CIVI-NEXT:    s_mov_b32 s32, 0
; CIVI-NEXT:    s_mov_b32 flat_scratch_lo, s7
; CIVI-NEXT:    s_getpc_b64 s[4:5]
; CIVI-NEXT:    s_add_u32 s4, s4, use_queue_ptr_addrspacecast@rel32@lo+4
; CIVI-NEXT:    s_addc_u32 s5, s5, use_queue_ptr_addrspacecast@rel32@hi+12
; CIVI-NEXT:    s_swappc_b64 s[30:31], s[4:5]
; CIVI-NEXT:    s_endpgm
;
; GFX9-LABEL: kern_indirect_use_queue_ptr_addrspacecast:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_add_u32 flat_scratch_lo, s6, s9
; GFX9-NEXT:    s_addc_u32 flat_scratch_hi, s7, 0
; GFX9-NEXT:    s_add_u32 s0, s0, s9
; GFX9-NEXT:    s_addc_u32 s1, s1, 0
; GFX9-NEXT:    s_mov_b32 s32, 0
; GFX9-NEXT:    s_getpc_b64 s[4:5]
; GFX9-NEXT:    s_add_u32 s4, s4, use_queue_ptr_addrspacecast@rel32@lo+4
; GFX9-NEXT:    s_addc_u32 s5, s5, use_queue_ptr_addrspacecast@rel32@hi+12
; GFX9-NEXT:    s_swappc_b64 s[30:31], s[4:5]
; GFX9-NEXT:    s_endpgm
  call void @use_queue_ptr_addrspacecast()
  ret void
}

; Not really supported in callable functions.
; GCN-LABEL: {{^}}use_kernarg_segment_ptr:
; GCN: s_mov_b64 [[PTR:s\[[0-9]+:[0-9]+\]]], 0
; GCN: s_load_dword s{{[0-9]+}}, [[PTR]], 0x0
define hidden void @use_kernarg_segment_ptr() #1 {
; GCN-LABEL: use_kernarg_segment_ptr:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    s_mov_b64 s[4:5], 0
; GCN-NEXT:    s_load_dword s4, s[4:5], 0x0
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %kernarg_segment_ptr = call noalias ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr() #0
  %value = load volatile i32, ptr addrspace(4) %kernarg_segment_ptr
  ret void
}

; GCN-LABEL: {{^}}use_implicitarg_ptr:
; GCN: s_load_dword s{{[0-9]+}}, s[8:9]
define hidden void @use_implicitarg_ptr() #1 {
; GCN-LABEL: use_implicitarg_ptr:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    s_load_dword s4, s[8:9], 0x0
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %implicit.arg.ptr = call noalias ptr addrspace(4) @llvm.amdgcn.implicitarg.ptr() #0
  %value = load volatile i32, ptr addrspace(4) %implicit.arg.ptr
  ret void
}

; GCN-LABEL: {{^}}kern_indirect_use_kernarg_segment_ptr:
; GCN: .amdhsa_user_sgpr_kernarg_segment_ptr 1
define amdgpu_kernel void @kern_indirect_use_kernarg_segment_ptr(i32) #1 {
; CIVI-LABEL: kern_indirect_use_kernarg_segment_ptr:
; CIVI:       ; %bb.0:
; CIVI-NEXT:    s_add_i32 s6, s6, s9
; CIVI-NEXT:    s_lshr_b32 flat_scratch_hi, s6, 8
; CIVI-NEXT:    s_add_u32 s0, s0, s9
; CIVI-NEXT:    s_addc_u32 s1, s1, 0
; CIVI-NEXT:    s_mov_b32 s32, 0
; CIVI-NEXT:    s_mov_b32 flat_scratch_lo, s7
; CIVI-NEXT:    s_getpc_b64 s[4:5]
; CIVI-NEXT:    s_add_u32 s4, s4, use_kernarg_segment_ptr@rel32@lo+4
; CIVI-NEXT:    s_addc_u32 s5, s5, use_kernarg_segment_ptr@rel32@hi+12
; CIVI-NEXT:    s_swappc_b64 s[30:31], s[4:5]
; CIVI-NEXT:    s_endpgm
;
; GFX9-LABEL: kern_indirect_use_kernarg_segment_ptr:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_add_u32 flat_scratch_lo, s6, s9
; GFX9-NEXT:    s_addc_u32 flat_scratch_hi, s7, 0
; GFX9-NEXT:    s_add_u32 s0, s0, s9
; GFX9-NEXT:    s_addc_u32 s1, s1, 0
; GFX9-NEXT:    s_mov_b32 s32, 0
; GFX9-NEXT:    s_getpc_b64 s[4:5]
; GFX9-NEXT:    s_add_u32 s4, s4, use_kernarg_segment_ptr@rel32@lo+4
; GFX9-NEXT:    s_addc_u32 s5, s5, use_kernarg_segment_ptr@rel32@hi+12
; GFX9-NEXT:    s_swappc_b64 s[30:31], s[4:5]
; GFX9-NEXT:    s_endpgm
  call void @use_kernarg_segment_ptr()
  ret void
}

; GCN-LABEL: {{^}}use_dispatch_id:
; GCN: ; use s[10:11]
define hidden void @use_dispatch_id() #1 {
; GCN-LABEL: use_dispatch_id:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    ;;#ASMSTART
; GCN-NEXT:    ; use s[10:11]
; GCN-NEXT:    ;;#ASMEND
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %id = call i64 @llvm.amdgcn.dispatch.id()
  call void asm sideeffect "; use $0", "s"(i64 %id)
  ret void
}

; No kernarg segment so that there is a mov to check. With kernarg
; pointer enabled, it happens to end up in the right place anyway.

; GCN-LABEL: {{^}}kern_indirect_use_dispatch_id:
; GCN: s_mov_b64 s[10:11], s[4:5]
; GCN: .amdhsa_user_sgpr_dispatch_id 1
define amdgpu_kernel void @kern_indirect_use_dispatch_id() #1 {
; CIVI-LABEL: kern_indirect_use_dispatch_id:
; CIVI:       ; %bb.0:
; CIVI-NEXT:    s_add_i32 s6, s6, s9
; CIVI-NEXT:    s_lshr_b32 flat_scratch_hi, s6, 8
; CIVI-NEXT:    s_add_u32 s0, s0, s9
; CIVI-NEXT:    s_addc_u32 s1, s1, 0
; CIVI-NEXT:    s_mov_b64 s[10:11], s[4:5]
; CIVI-NEXT:    s_mov_b32 s32, 0
; CIVI-NEXT:    s_mov_b32 flat_scratch_lo, s7
; CIVI-NEXT:    s_getpc_b64 s[6:7]
; CIVI-NEXT:    s_add_u32 s6, s6, use_dispatch_id@rel32@lo+4
; CIVI-NEXT:    s_addc_u32 s7, s7, use_dispatch_id@rel32@hi+12
; CIVI-NEXT:    s_swappc_b64 s[30:31], s[6:7]
; CIVI-NEXT:    s_endpgm
;
; GFX9-LABEL: kern_indirect_use_dispatch_id:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_add_u32 flat_scratch_lo, s6, s9
; GFX9-NEXT:    s_addc_u32 flat_scratch_hi, s7, 0
; GFX9-NEXT:    s_add_u32 s0, s0, s9
; GFX9-NEXT:    s_addc_u32 s1, s1, 0
; GFX9-NEXT:    s_mov_b64 s[10:11], s[4:5]
; GFX9-NEXT:    s_mov_b32 s32, 0
; GFX9-NEXT:    s_getpc_b64 s[6:7]
; GFX9-NEXT:    s_add_u32 s6, s6, use_dispatch_id@rel32@lo+4
; GFX9-NEXT:    s_addc_u32 s7, s7, use_dispatch_id@rel32@hi+12
; GFX9-NEXT:    s_swappc_b64 s[30:31], s[6:7]
; GFX9-NEXT:    s_endpgm
  call void @use_dispatch_id()
  ret void
}

; GCN-LABEL: {{^}}use_workgroup_id_x:
; GCN: s_waitcnt
; GCN: ; use s12
define hidden void @use_workgroup_id_x() #1 {
; GCN-LABEL: use_workgroup_id_x:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    ;;#ASMSTART
; GCN-NEXT:    ; use s12
; GCN-NEXT:    ;;#ASMEND
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %val = call i32 @llvm.amdgcn.workgroup.id.x()
  call void asm sideeffect "; use $0", "s"(i32 %val)
  ret void
}

; GCN-LABEL: {{^}}use_stack_workgroup_id_x:
; GCN: s_waitcnt
; GCN-NOT: s32
; GCN: buffer_store_dword v0, off, s[0:3], s32{{$}}
; GCN: ; use s12
; GCN: s_setpc_b64
define hidden void @use_stack_workgroup_id_x() #1 {
; GCN-LABEL: use_stack_workgroup_id_x:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_mov_b32_e32 v0, 0
; GCN-NEXT:    buffer_store_dword v0, off, s[0:3], s32
; GCN-NEXT:    s_waitcnt vmcnt(0)
; GCN-NEXT:    ;;#ASMSTART
; GCN-NEXT:    ; use s12
; GCN-NEXT:    ;;#ASMEND
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %alloca = alloca i32, addrspace(5)
  store volatile i32 0, ptr addrspace(5) %alloca
  %val = call i32 @llvm.amdgcn.workgroup.id.x()
  call void asm sideeffect "; use $0", "s"(i32 %val)
  ret void
}

; GCN-LABEL: {{^}}use_workgroup_id_y:
; GCN: s_waitcnt
; GCN: ; use s13
define hidden void @use_workgroup_id_y() #1 {
; GCN-LABEL: use_workgroup_id_y:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    ;;#ASMSTART
; GCN-NEXT:    ; use s13
; GCN-NEXT:    ;;#ASMEND
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %val = call i32 @llvm.amdgcn.workgroup.id.y()
  call void asm sideeffect "; use $0", "s"(i32 %val)
  ret void
}

; GCN-LABEL: {{^}}use_workgroup_id_z:
; GCN: s_waitcnt
; GCN: ; use s14
define hidden void @use_workgroup_id_z() #1 {
; GCN-LABEL: use_workgroup_id_z:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    ;;#ASMSTART
; GCN-NEXT:    ; use s14
; GCN-NEXT:    ;;#ASMEND
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %val = call i32 @llvm.amdgcn.workgroup.id.z()
  call void asm sideeffect "; use $0", "s"(i32 %val)
  ret void
}

; GCN-LABEL: {{^}}use_workgroup_id_xy:
; GCN: ; use s12
; GCN: ; use s13
define hidden void @use_workgroup_id_xy() #1 {
; GCN-LABEL: use_workgroup_id_xy:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    ;;#ASMSTART
; GCN-NEXT:    ; use s12
; GCN-NEXT:    ;;#ASMEND
; GCN-NEXT:    ;;#ASMSTART
; GCN-NEXT:    ; use s13
; GCN-NEXT:    ;;#ASMEND
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %val0 = call i32 @llvm.amdgcn.workgroup.id.x()
  %val1 = call i32 @llvm.amdgcn.workgroup.id.y()
  call void asm sideeffect "; use $0", "s"(i32 %val0)
  call void asm sideeffect "; use $0", "s"(i32 %val1)
  ret void
}

; GCN-LABEL: {{^}}use_workgroup_id_xyz:
; GCN: ; use s12
; GCN: ; use s13
; GCN: ; use s14
define hidden void @use_workgroup_id_xyz() #1 {
; GCN-LABEL: use_workgroup_id_xyz:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    ;;#ASMSTART
; GCN-NEXT:    ; use s12
; GCN-NEXT:    ;;#ASMEND
; GCN-NEXT:    ;;#ASMSTART
; GCN-NEXT:    ; use s13
; GCN-NEXT:    ;;#ASMEND
; GCN-NEXT:    ;;#ASMSTART
; GCN-NEXT:    ; use s14
; GCN-NEXT:    ;;#ASMEND
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %val0 = call i32 @llvm.amdgcn.workgroup.id.x()
  %val1 = call i32 @llvm.amdgcn.workgroup.id.y()
  %val2 = call i32 @llvm.amdgcn.workgroup.id.z()
  call void asm sideeffect "; use $0", "s"(i32 %val0)
  call void asm sideeffect "; use $0", "s"(i32 %val1)
  call void asm sideeffect "; use $0", "s"(i32 %val2)
  ret void
}

; GCN-LABEL: {{^}}use_workgroup_id_xz:
; GCN: ; use s12
; GCN: ; use s14
define hidden void @use_workgroup_id_xz() #1 {
; GCN-LABEL: use_workgroup_id_xz:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    ;;#ASMSTART
; GCN-NEXT:    ; use s12
; GCN-NEXT:    ;;#ASMEND
; GCN-NEXT:    ;;#ASMSTART
; GCN-NEXT:    ; use s14
; GCN-NEXT:    ;;#ASMEND
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %val0 = call i32 @llvm.amdgcn.workgroup.id.x()
  %val1 = call i32 @llvm.amdgcn.workgroup.id.z()
  call void asm sideeffect "; use $0", "s"(i32 %val0)
  call void asm sideeffect "; use $0", "s"(i32 %val1)
  ret void
}

; GCN-LABEL: {{^}}use_workgroup_id_yz:
; GCN: ; use s13
; GCN: ; use s14
define hidden void @use_workgroup_id_yz() #1 {
; GCN-LABEL: use_workgroup_id_yz:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    ;;#ASMSTART
; GCN-NEXT:    ; use s13
; GCN-NEXT:    ;;#ASMEND
; GCN-NEXT:    ;;#ASMSTART
; GCN-NEXT:    ; use s14
; GCN-NEXT:    ;;#ASMEND
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %val0 = call i32 @llvm.amdgcn.workgroup.id.y()
  %val1 = call i32 @llvm.amdgcn.workgroup.id.z()
  call void asm sideeffect "; use $0", "s"(i32 %val0)
  call void asm sideeffect "; use $0", "s"(i32 %val1)
  ret void
}

; GCN-LABEL: {{^}}kern_indirect_use_workgroup_id_x:
; GCN-NOT: s6
; GCN: s_mov_b32 s12, s6
; GCN: s_mov_b32 s32, 0
; GCN: s_getpc_b64 s[4:5]
; GCN-NEXT: s_add_u32 s4, s4, use_workgroup_id_x@rel32@lo+4
; GCN-NEXT: s_addc_u32 s5, s5, use_workgroup_id_x@rel32@hi+12
; GCN: s_swappc_b64
; GCN-NEXT: s_endpgm

; GCN: .amdhsa_system_sgpr_workgroup_id_x 1
; GCN: .amdhsa_system_sgpr_workgroup_id_y 0
; GCN: .amdhsa_system_sgpr_workgroup_id_z 0
define amdgpu_kernel void @kern_indirect_use_workgroup_id_x() #1 {
; CIVI-LABEL: kern_indirect_use_workgroup_id_x:
; CIVI:       ; %bb.0:
; CIVI-NEXT:    s_add_i32 s4, s4, s7
; CIVI-NEXT:    s_lshr_b32 flat_scratch_hi, s4, 8
; CIVI-NEXT:    s_add_u32 s0, s0, s7
; CIVI-NEXT:    s_addc_u32 s1, s1, 0
; CIVI-NEXT:    s_mov_b32 s12, s6
; CIVI-NEXT:    s_mov_b32 s32, 0
; CIVI-NEXT:    s_mov_b32 flat_scratch_lo, s5
; CIVI-NEXT:    s_getpc_b64 s[4:5]
; CIVI-NEXT:    s_add_u32 s4, s4, use_workgroup_id_x@rel32@lo+4
; CIVI-NEXT:    s_addc_u32 s5, s5, use_workgroup_id_x@rel32@hi+12
; CIVI-NEXT:    s_swappc_b64 s[30:31], s[4:5]
; CIVI-NEXT:    s_endpgm
;
; GFX9-LABEL: kern_indirect_use_workgroup_id_x:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_add_u32 flat_scratch_lo, s4, s7
; GFX9-NEXT:    s_addc_u32 flat_scratch_hi, s5, 0
; GFX9-NEXT:    s_add_u32 s0, s0, s7
; GFX9-NEXT:    s_addc_u32 s1, s1, 0
; GFX9-NEXT:    s_mov_b32 s12, s6
; GFX9-NEXT:    s_mov_b32 s32, 0
; GFX9-NEXT:    s_getpc_b64 s[4:5]
; GFX9-NEXT:    s_add_u32 s4, s4, use_workgroup_id_x@rel32@lo+4
; GFX9-NEXT:    s_addc_u32 s5, s5, use_workgroup_id_x@rel32@hi+12
; GFX9-NEXT:    s_swappc_b64 s[30:31], s[4:5]
; GFX9-NEXT:    s_endpgm
  call void @use_workgroup_id_x()
  ret void
}

; GCN-LABEL: {{^}}kern_indirect_use_workgroup_id_y:
; GCN-NOT: s12
; GCN: s_mov_b32 s13, s7
; GCN-NOT: s12
; GCN: s_mov_b32 s32, 0
; GCN: s_swappc_b64

; GCN: .amdhsa_system_sgpr_workgroup_id_x 1
; GCN: .amdhsa_system_sgpr_workgroup_id_y 1
; GCN: .amdhsa_system_sgpr_workgroup_id_z 0
define amdgpu_kernel void @kern_indirect_use_workgroup_id_y() #1 {
; CIVI-LABEL: kern_indirect_use_workgroup_id_y:
; CIVI:       ; %bb.0:
; CIVI-NEXT:    s_add_i32 s4, s4, s8
; CIVI-NEXT:    s_lshr_b32 flat_scratch_hi, s4, 8
; CIVI-NEXT:    s_add_u32 s0, s0, s8
; CIVI-NEXT:    s_addc_u32 s1, s1, 0
; CIVI-NEXT:    s_mov_b32 s13, s7
; CIVI-NEXT:    s_mov_b32 s32, 0
; CIVI-NEXT:    s_mov_b32 flat_scratch_lo, s5
; CIVI-NEXT:    s_getpc_b64 s[4:5]
; CIVI-NEXT:    s_add_u32 s4, s4, use_workgroup_id_y@rel32@lo+4
; CIVI-NEXT:    s_addc_u32 s5, s5, use_workgroup_id_y@rel32@hi+12
; CIVI-NEXT:    s_swappc_b64 s[30:31], s[4:5]
; CIVI-NEXT:    s_endpgm
;
; GFX9-LABEL: kern_indirect_use_workgroup_id_y:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_add_u32 flat_scratch_lo, s4, s8
; GFX9-NEXT:    s_addc_u32 flat_scratch_hi, s5, 0
; GFX9-NEXT:    s_add_u32 s0, s0, s8
; GFX9-NEXT:    s_addc_u32 s1, s1, 0
; GFX9-NEXT:    s_mov_b32 s13, s7
; GFX9-NEXT:    s_mov_b32 s32, 0
; GFX9-NEXT:    s_getpc_b64 s[4:5]
; GFX9-NEXT:    s_add_u32 s4, s4, use_workgroup_id_y@rel32@lo+4
; GFX9-NEXT:    s_addc_u32 s5, s5, use_workgroup_id_y@rel32@hi+12
; GFX9-NEXT:    s_swappc_b64 s[30:31], s[4:5]
; GFX9-NEXT:    s_endpgm
  call void @use_workgroup_id_y()
  ret void
}

; GCN-LABEL: {{^}}kern_indirect_use_workgroup_id_z:
; GCN-NOT: s12
; GCN-NOT: s13
; GCN: s_mov_b32 s14, s7
; GCN-NOT: s12
; GCN-NOT: s13

; GCN: s_mov_b32 s32, 0
; GCN: s_swappc_b64

; GCN: .amdhsa_system_sgpr_workgroup_id_x 1
; GCN: .amdhsa_system_sgpr_workgroup_id_y 0
; GCN: .amdhsa_system_sgpr_workgroup_id_z 1
define amdgpu_kernel void @kern_indirect_use_workgroup_id_z() #1 {
; CIVI-LABEL: kern_indirect_use_workgroup_id_z:
; CIVI:       ; %bb.0:
; CIVI-NEXT:    s_add_i32 s4, s4, s8
; CIVI-NEXT:    s_lshr_b32 flat_scratch_hi, s4, 8
; CIVI-NEXT:    s_add_u32 s0, s0, s8
; CIVI-NEXT:    s_addc_u32 s1, s1, 0
; CIVI-NEXT:    s_mov_b32 s14, s7
; CIVI-NEXT:    s_mov_b32 s32, 0
; CIVI-NEXT:    s_mov_b32 flat_scratch_lo, s5
; CIVI-NEXT:    s_getpc_b64 s[4:5]
; CIVI-NEXT:    s_add_u32 s4, s4, use_workgroup_id_z@rel32@lo+4
; CIVI-NEXT:    s_addc_u32 s5, s5, use_workgroup_id_z@rel32@hi+12
; CIVI-NEXT:    s_swappc_b64 s[30:31], s[4:5]
; CIVI-NEXT:    s_endpgm
;
; GFX9-LABEL: kern_indirect_use_workgroup_id_z:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_add_u32 flat_scratch_lo, s4, s8
; GFX9-NEXT:    s_addc_u32 flat_scratch_hi, s5, 0
; GFX9-NEXT:    s_add_u32 s0, s0, s8
; GFX9-NEXT:    s_addc_u32 s1, s1, 0
; GFX9-NEXT:    s_mov_b32 s14, s7
; GFX9-NEXT:    s_mov_b32 s32, 0
; GFX9-NEXT:    s_getpc_b64 s[4:5]
; GFX9-NEXT:    s_add_u32 s4, s4, use_workgroup_id_z@rel32@lo+4
; GFX9-NEXT:    s_addc_u32 s5, s5, use_workgroup_id_z@rel32@hi+12
; GFX9-NEXT:    s_swappc_b64 s[30:31], s[4:5]
; GFX9-NEXT:    s_endpgm
  call void @use_workgroup_id_z()
  ret void
}

; GCN-LABEL: {{^}}kern_indirect_use_workgroup_id_xy:
; GCN-NOT: s14
; GCN: s_mov_b32 s12, s6
; GCN-NEXT: s_mov_b32 s13, s7
; GCN-NOT: s14

; GCN: s_mov_b32 s32, 0
; GCN: s_swappc_b64

; GCN: .amdhsa_system_sgpr_workgroup_id_x 1
; GCN: .amdhsa_system_sgpr_workgroup_id_y 1
; GCN: .amdhsa_system_sgpr_workgroup_id_z 0
define amdgpu_kernel void @kern_indirect_use_workgroup_id_xy() #1 {
; CIVI-LABEL: kern_indirect_use_workgroup_id_xy:
; CIVI:       ; %bb.0:
; CIVI-NEXT:    s_add_i32 s4, s4, s8
; CIVI-NEXT:    s_lshr_b32 flat_scratch_hi, s4, 8
; CIVI-NEXT:    s_add_u32 s0, s0, s8
; CIVI-NEXT:    s_addc_u32 s1, s1, 0
; CIVI-NEXT:    s_mov_b32 s12, s6
; CIVI-NEXT:    s_mov_b32 s13, s7
; CIVI-NEXT:    s_mov_b32 s32, 0
; CIVI-NEXT:    s_mov_b32 flat_scratch_lo, s5
; CIVI-NEXT:    s_getpc_b64 s[4:5]
; CIVI-NEXT:    s_add_u32 s4, s4, use_workgroup_id_xy@rel32@lo+4
; CIVI-NEXT:    s_addc_u32 s5, s5, use_workgroup_id_xy@rel32@hi+12
; CIVI-NEXT:    s_swappc_b64 s[30:31], s[4:5]
; CIVI-NEXT:    s_endpgm
;
; GFX9-LABEL: kern_indirect_use_workgroup_id_xy:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_add_u32 flat_scratch_lo, s4, s8
; GFX9-NEXT:    s_addc_u32 flat_scratch_hi, s5, 0
; GFX9-NEXT:    s_add_u32 s0, s0, s8
; GFX9-NEXT:    s_addc_u32 s1, s1, 0
; GFX9-NEXT:    s_mov_b32 s12, s6
; GFX9-NEXT:    s_mov_b32 s13, s7
; GFX9-NEXT:    s_mov_b32 s32, 0
; GFX9-NEXT:    s_getpc_b64 s[4:5]
; GFX9-NEXT:    s_add_u32 s4, s4, use_workgroup_id_xy@rel32@lo+4
; GFX9-NEXT:    s_addc_u32 s5, s5, use_workgroup_id_xy@rel32@hi+12
; GFX9-NEXT:    s_swappc_b64 s[30:31], s[4:5]
; GFX9-NEXT:    s_endpgm
  call void @use_workgroup_id_xy()
  ret void
}

; GCN-LABEL: {{^}}kern_indirect_use_workgroup_id_xyz:
; GCN: s_mov_b32 s12, s6
; GCN: s_mov_b32 s13, s7
; GCN: s_mov_b32 s14, s8
; GCN: s_mov_b32 s32, 0
; GCN: s_swappc_b64

; GCN: .amdhsa_system_sgpr_workgroup_id_x 1
; GCN: .amdhsa_system_sgpr_workgroup_id_y 1
; GCN: .amdhsa_system_sgpr_workgroup_id_z 1
define amdgpu_kernel void @kern_indirect_use_workgroup_id_xyz() #1 {
; CIVI-LABEL: kern_indirect_use_workgroup_id_xyz:
; CIVI:       ; %bb.0:
; CIVI-NEXT:    s_add_i32 s4, s4, s9
; CIVI-NEXT:    s_lshr_b32 flat_scratch_hi, s4, 8
; CIVI-NEXT:    s_add_u32 s0, s0, s9
; CIVI-NEXT:    s_addc_u32 s1, s1, 0
; CIVI-NEXT:    s_mov_b32 s12, s6
; CIVI-NEXT:    s_mov_b32 s13, s7
; CIVI-NEXT:    s_mov_b32 s14, s8
; CIVI-NEXT:    s_mov_b32 s32, 0
; CIVI-NEXT:    s_mov_b32 flat_scratch_lo, s5
; CIVI-NEXT:    s_getpc_b64 s[4:5]
; CIVI-NEXT:    s_add_u32 s4, s4, use_workgroup_id_xyz@rel32@lo+4
; CIVI-NEXT:    s_addc_u32 s5, s5, use_workgroup_id_xyz@rel32@hi+12
; CIVI-NEXT:    s_swappc_b64 s[30:31], s[4:5]
; CIVI-NEXT:    s_endpgm
;
; GFX9-LABEL: kern_indirect_use_workgroup_id_xyz:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_add_u32 flat_scratch_lo, s4, s9
; GFX9-NEXT:    s_addc_u32 flat_scratch_hi, s5, 0
; GFX9-NEXT:    s_add_u32 s0, s0, s9
; GFX9-NEXT:    s_addc_u32 s1, s1, 0
; GFX9-NEXT:    s_mov_b32 s12, s6
; GFX9-NEXT:    s_mov_b32 s13, s7
; GFX9-NEXT:    s_mov_b32 s14, s8
; GFX9-NEXT:    s_mov_b32 s32, 0
; GFX9-NEXT:    s_getpc_b64 s[4:5]
; GFX9-NEXT:    s_add_u32 s4, s4, use_workgroup_id_xyz@rel32@lo+4
; GFX9-NEXT:    s_addc_u32 s5, s5, use_workgroup_id_xyz@rel32@hi+12
; GFX9-NEXT:    s_swappc_b64 s[30:31], s[4:5]
; GFX9-NEXT:    s_endpgm
  call void @use_workgroup_id_xyz()
  ret void
}

; GCN-LABEL: {{^}}kern_indirect_use_workgroup_id_xz:

; GCN-NOT: s13
; GCN: s_mov_b32 s12, s6
; GCN-NEXT: s_mov_b32 s14, s7
; GCN-NOT: s13

; GCN: s_mov_b32 s32, 0
; GCN: s_swappc_b64

; GCN: .amdhsa_system_sgpr_workgroup_id_x 1
; GCN: .amdhsa_system_sgpr_workgroup_id_y 0
; GCN: .amdhsa_system_sgpr_workgroup_id_z 1
define amdgpu_kernel void @kern_indirect_use_workgroup_id_xz() #1 {
; CIVI-LABEL: kern_indirect_use_workgroup_id_xz:
; CIVI:       ; %bb.0:
; CIVI-NEXT:    s_add_i32 s4, s4, s8
; CIVI-NEXT:    s_lshr_b32 flat_scratch_hi, s4, 8
; CIVI-NEXT:    s_add_u32 s0, s0, s8
; CIVI-NEXT:    s_addc_u32 s1, s1, 0
; CIVI-NEXT:    s_mov_b32 s12, s6
; CIVI-NEXT:    s_mov_b32 s14, s7
; CIVI-NEXT:    s_mov_b32 s32, 0
; CIVI-NEXT:    s_mov_b32 flat_scratch_lo, s5
; CIVI-NEXT:    s_getpc_b64 s[4:5]
; CIVI-NEXT:    s_add_u32 s4, s4, use_workgroup_id_xz@rel32@lo+4
; CIVI-NEXT:    s_addc_u32 s5, s5, use_workgroup_id_xz@rel32@hi+12
; CIVI-NEXT:    s_swappc_b64 s[30:31], s[4:5]
; CIVI-NEXT:    s_endpgm
;
; GFX9-LABEL: kern_indirect_use_workgroup_id_xz:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_add_u32 flat_scratch_lo, s4, s8
; GFX9-NEXT:    s_addc_u32 flat_scratch_hi, s5, 0
; GFX9-NEXT:    s_add_u32 s0, s0, s8
; GFX9-NEXT:    s_addc_u32 s1, s1, 0
; GFX9-NEXT:    s_mov_b32 s12, s6
; GFX9-NEXT:    s_mov_b32 s14, s7
; GFX9-NEXT:    s_mov_b32 s32, 0
; GFX9-NEXT:    s_getpc_b64 s[4:5]
; GFX9-NEXT:    s_add_u32 s4, s4, use_workgroup_id_xz@rel32@lo+4
; GFX9-NEXT:    s_addc_u32 s5, s5, use_workgroup_id_xz@rel32@hi+12
; GFX9-NEXT:    s_swappc_b64 s[30:31], s[4:5]
; GFX9-NEXT:    s_endpgm
  call void @use_workgroup_id_xz()
  ret void
}

; GCN-LABEL: {{^}}kern_indirect_use_workgroup_id_yz:

; GCN: s_mov_b32 s13, s7
; GCN: s_mov_b32 s14, s8

; GCN: s_mov_b32 s32, 0
; GCN: s_swappc_b64

; GCN: .amdhsa_system_sgpr_workgroup_id_x 1
; GCN: .amdhsa_system_sgpr_workgroup_id_y 1
; GCN: .amdhsa_system_sgpr_workgroup_id_z 1
define amdgpu_kernel void @kern_indirect_use_workgroup_id_yz() #1 {
; CIVI-LABEL: kern_indirect_use_workgroup_id_yz:
; CIVI:       ; %bb.0:
; CIVI-NEXT:    s_add_i32 s4, s4, s9
; CIVI-NEXT:    s_lshr_b32 flat_scratch_hi, s4, 8
; CIVI-NEXT:    s_add_u32 s0, s0, s9
; CIVI-NEXT:    s_addc_u32 s1, s1, 0
; CIVI-NEXT:    s_mov_b32 s13, s7
; CIVI-NEXT:    s_mov_b32 s14, s8
; CIVI-NEXT:    s_mov_b32 s32, 0
; CIVI-NEXT:    s_mov_b32 flat_scratch_lo, s5
; CIVI-NEXT:    s_getpc_b64 s[4:5]
; CIVI-NEXT:    s_add_u32 s4, s4, use_workgroup_id_yz@rel32@lo+4
; CIVI-NEXT:    s_addc_u32 s5, s5, use_workgroup_id_yz@rel32@hi+12
; CIVI-NEXT:    s_swappc_b64 s[30:31], s[4:5]
; CIVI-NEXT:    s_endpgm
;
; GFX9-LABEL: kern_indirect_use_workgroup_id_yz:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_add_u32 flat_scratch_lo, s4, s9
; GFX9-NEXT:    s_addc_u32 flat_scratch_hi, s5, 0
; GFX9-NEXT:    s_add_u32 s0, s0, s9
; GFX9-NEXT:    s_addc_u32 s1, s1, 0
; GFX9-NEXT:    s_mov_b32 s13, s7
; GFX9-NEXT:    s_mov_b32 s14, s8
; GFX9-NEXT:    s_mov_b32 s32, 0
; GFX9-NEXT:    s_getpc_b64 s[4:5]
; GFX9-NEXT:    s_add_u32 s4, s4, use_workgroup_id_yz@rel32@lo+4
; GFX9-NEXT:    s_addc_u32 s5, s5, use_workgroup_id_yz@rel32@hi+12
; GFX9-NEXT:    s_swappc_b64 s[30:31], s[4:5]
; GFX9-NEXT:    s_endpgm
  call void @use_workgroup_id_yz()
  ret void
}

; Argument is in right place already
; GCN-LABEL: {{^}}func_indirect_use_workgroup_id_x:
; GCN-NOT: s12
; GCN-NOT: s13
; GCN-NOT: s14
; GCN: v_readlane_b32 s30, v40, 0
define hidden void @func_indirect_use_workgroup_id_x() #1 {
; GCN-LABEL: func_indirect_use_workgroup_id_x:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    s_mov_b32 s4, s33
; GCN-NEXT:    s_mov_b32 s33, s32
; GCN-NEXT:    s_or_saveexec_b64 s[6:7], -1
; GCN-NEXT:    buffer_store_dword v40, off, s[0:3], s33 ; 4-byte Folded Spill
; GCN-NEXT:    s_mov_b64 exec, s[6:7]
; GCN-NEXT:    v_writelane_b32 v40, s4, 2
; GCN-NEXT:    s_addk_i32 s32, 0x400
; GCN-NEXT:    v_writelane_b32 v40, s30, 0
; GCN-NEXT:    v_writelane_b32 v40, s31, 1
; GCN-NEXT:    s_getpc_b64 s[4:5]
; GCN-NEXT:    s_add_u32 s4, s4, use_workgroup_id_x@rel32@lo+4
; GCN-NEXT:    s_addc_u32 s5, s5, use_workgroup_id_x@rel32@hi+12
; GCN-NEXT:    s_swappc_b64 s[30:31], s[4:5]
; GCN-NEXT:    v_readlane_b32 s31, v40, 1
; GCN-NEXT:    v_readlane_b32 s30, v40, 0
; GCN-NEXT:    v_readlane_b32 s4, v40, 2
; GCN-NEXT:    s_or_saveexec_b64 s[6:7], -1
; GCN-NEXT:    buffer_load_dword v40, off, s[0:3], s33 ; 4-byte Folded Reload
; GCN-NEXT:    s_mov_b64 exec, s[6:7]
; GCN-NEXT:    s_addk_i32 s32, 0xfc00
; GCN-NEXT:    s_mov_b32 s33, s4
; GCN-NEXT:    s_waitcnt vmcnt(0)
; GCN-NEXT:    s_setpc_b64 s[30:31]
  call void @use_workgroup_id_x()
  ret void
}

; Argument is in right place already. We are free to clobber other
; SGPR arguments
; GCN-LABEL: {{^}}func_indirect_use_workgroup_id_y:
; GCN-NOT: s12
; GCN-NOT: s13
; GCN-NOT: s14
define hidden void @func_indirect_use_workgroup_id_y() #1 {
; GCN-LABEL: func_indirect_use_workgroup_id_y:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    s_mov_b32 s4, s33
; GCN-NEXT:    s_mov_b32 s33, s32
; GCN-NEXT:    s_or_saveexec_b64 s[6:7], -1
; GCN-NEXT:    buffer_store_dword v40, off, s[0:3], s33 ; 4-byte Folded Spill
; GCN-NEXT:    s_mov_b64 exec, s[6:7]
; GCN-NEXT:    v_writelane_b32 v40, s4, 2
; GCN-NEXT:    s_addk_i32 s32, 0x400
; GCN-NEXT:    v_writelane_b32 v40, s30, 0
; GCN-NEXT:    v_writelane_b32 v40, s31, 1
; GCN-NEXT:    s_getpc_b64 s[4:5]
; GCN-NEXT:    s_add_u32 s4, s4, use_workgroup_id_y@rel32@lo+4
; GCN-NEXT:    s_addc_u32 s5, s5, use_workgroup_id_y@rel32@hi+12
; GCN-NEXT:    s_swappc_b64 s[30:31], s[4:5]
; GCN-NEXT:    v_readlane_b32 s31, v40, 1
; GCN-NEXT:    v_readlane_b32 s30, v40, 0
; GCN-NEXT:    v_readlane_b32 s4, v40, 2
; GCN-NEXT:    s_or_saveexec_b64 s[6:7], -1
; GCN-NEXT:    buffer_load_dword v40, off, s[0:3], s33 ; 4-byte Folded Reload
; GCN-NEXT:    s_mov_b64 exec, s[6:7]
; GCN-NEXT:    s_addk_i32 s32, 0xfc00
; GCN-NEXT:    s_mov_b32 s33, s4
; GCN-NEXT:    s_waitcnt vmcnt(0)
; GCN-NEXT:    s_setpc_b64 s[30:31]
  call void @use_workgroup_id_y()
  ret void
}

; GCN-LABEL: {{^}}func_indirect_use_workgroup_id_z:
; GCN-NOT: s12
; GCN-NOT: s13
; GCN-NOT: s14
define hidden void @func_indirect_use_workgroup_id_z() #1 {
; GCN-LABEL: func_indirect_use_workgroup_id_z:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    s_mov_b32 s4, s33
; GCN-NEXT:    s_mov_b32 s33, s32
; GCN-NEXT:    s_or_saveexec_b64 s[6:7], -1
; GCN-NEXT:    buffer_store_dword v40, off, s[0:3], s33 ; 4-byte Folded Spill
; GCN-NEXT:    s_mov_b64 exec, s[6:7]
; GCN-NEXT:    v_writelane_b32 v40, s4, 2
; GCN-NEXT:    s_addk_i32 s32, 0x400
; GCN-NEXT:    v_writelane_b32 v40, s30, 0
; GCN-NEXT:    v_writelane_b32 v40, s31, 1
; GCN-NEXT:    s_getpc_b64 s[4:5]
; GCN-NEXT:    s_add_u32 s4, s4, use_workgroup_id_z@rel32@lo+4
; GCN-NEXT:    s_addc_u32 s5, s5, use_workgroup_id_z@rel32@hi+12
; GCN-NEXT:    s_swappc_b64 s[30:31], s[4:5]
; GCN-NEXT:    v_readlane_b32 s31, v40, 1
; GCN-NEXT:    v_readlane_b32 s30, v40, 0
; GCN-NEXT:    v_readlane_b32 s4, v40, 2
; GCN-NEXT:    s_or_saveexec_b64 s[6:7], -1
; GCN-NEXT:    buffer_load_dword v40, off, s[0:3], s33 ; 4-byte Folded Reload
; GCN-NEXT:    s_mov_b64 exec, s[6:7]
; GCN-NEXT:    s_addk_i32 s32, 0xfc00
; GCN-NEXT:    s_mov_b32 s33, s4
; GCN-NEXT:    s_waitcnt vmcnt(0)
; GCN-NEXT:    s_setpc_b64 s[30:31]
  call void @use_workgroup_id_z()
  ret void
}

; GCN-LABEL: {{^}}other_arg_use_workgroup_id_x:
; CIVI: flat_store_dword v{{\[[0-9]+:[0-9]+\]}}, v0
; GFX9: global_store_dword v{{\[[0-9]+:[0-9]+\]}}, v0, off
; GCN: ; use s12
define hidden void @other_arg_use_workgroup_id_x(i32 %arg0) #1 {
; CIVI-LABEL: other_arg_use_workgroup_id_x:
; CIVI:       ; %bb.0:
; CIVI-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CIVI-NEXT:    flat_store_dword v[0:1], v0
; CIVI-NEXT:    s_waitcnt vmcnt(0)
; CIVI-NEXT:    ;;#ASMSTART
; CIVI-NEXT:    ; use s12
; CIVI-NEXT:    ;;#ASMEND
; CIVI-NEXT:    s_setpc_b64 s[30:31]
;
; GFX9-LABEL: other_arg_use_workgroup_id_x:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_store_dword v[0:1], v0, off
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    ;;#ASMSTART
; GFX9-NEXT:    ; use s12
; GFX9-NEXT:    ;;#ASMEND
; GFX9-NEXT:    s_setpc_b64 s[30:31]
  %val = call i32 @llvm.amdgcn.workgroup.id.x()
  store volatile i32 %arg0, ptr addrspace(1) undef
  call void asm sideeffect "; use $0", "s"(i32 %val)
  ret void
}

; GCN-LABEL: {{^}}other_arg_use_workgroup_id_y:
; CIVI: flat_store_dword v{{\[[0-9]+:[0-9]+\]}}, v0
; GFX9: global_store_dword v{{\[[0-9]+:[0-9]+\]}}, v0, off
; GCN: ; use s13
define hidden void @other_arg_use_workgroup_id_y(i32 %arg0) #1 {
; CIVI-LABEL: other_arg_use_workgroup_id_y:
; CIVI:       ; %bb.0:
; CIVI-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CIVI-NEXT:    flat_store_dword v[0:1], v0
; CIVI-NEXT:    s_waitcnt vmcnt(0)
; CIVI-NEXT:    ;;#ASMSTART
; CIVI-NEXT:    ; use s13
; CIVI-NEXT:    ;;#ASMEND
; CIVI-NEXT:    s_setpc_b64 s[30:31]
;
; GFX9-LABEL: other_arg_use_workgroup_id_y:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_store_dword v[0:1], v0, off
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    ;;#ASMSTART
; GFX9-NEXT:    ; use s13
; GFX9-NEXT:    ;;#ASMEND
; GFX9-NEXT:    s_setpc_b64 s[30:31]
  %val = call i32 @llvm.amdgcn.workgroup.id.y()
  store volatile i32 %arg0, ptr addrspace(1) undef
  call void asm sideeffect "; use $0", "s"(i32 %val)
  ret void
}

; GCN-LABEL: {{^}}other_arg_use_workgroup_id_z:
; CIVI: flat_store_dword v{{\[[0-9]+:[0-9]+\]}}, v0
; GFX9: global_store_dword v{{\[[0-9]+:[0-9]+\]}}, v0, off
; GCN: ; use s14
define hidden void @other_arg_use_workgroup_id_z(i32 %arg0) #1 {
; CIVI-LABEL: other_arg_use_workgroup_id_z:
; CIVI:       ; %bb.0:
; CIVI-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CIVI-NEXT:    flat_store_dword v[0:1], v0
; CIVI-NEXT:    s_waitcnt vmcnt(0)
; CIVI-NEXT:    ;;#ASMSTART
; CIVI-NEXT:    ; use s14
; CIVI-NEXT:    ;;#ASMEND
; CIVI-NEXT:    s_setpc_b64 s[30:31]
;
; GFX9-LABEL: other_arg_use_workgroup_id_z:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_store_dword v[0:1], v0, off
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    ;;#ASMSTART
; GFX9-NEXT:    ; use s14
; GFX9-NEXT:    ;;#ASMEND
; GFX9-NEXT:    s_setpc_b64 s[30:31]
  %val = call i32 @llvm.amdgcn.workgroup.id.z()
  store volatile i32 %arg0, ptr addrspace(1) undef
  call void asm sideeffect "; use $0", "s"(i32 %val)
  ret void
}

; GCN-LABEL: {{^}}kern_indirect_other_arg_use_workgroup_id_x:

; GCN-NOT: s13
; GCN-NOT: s14
; GCN-DAG: s_mov_b32 s12, s6
; GCN-DAG: v_mov_b32_e32 v0, 0x22b
; GCN-NOT: s13
; GCN-NOT: s14

; GCN-DAG: s_mov_b32 s32, 0
; GCN: s_swappc_b64

; GCN: .amdhsa_system_sgpr_workgroup_id_x 1
; GCN: .amdhsa_system_sgpr_workgroup_id_y 0
; GCN: .amdhsa_system_sgpr_workgroup_id_z 0
define amdgpu_kernel void @kern_indirect_other_arg_use_workgroup_id_x() #1 {
; CIVI-LABEL: kern_indirect_other_arg_use_workgroup_id_x:
; CIVI:       ; %bb.0:
; CIVI-NEXT:    s_add_i32 s4, s4, s7
; CIVI-NEXT:    s_lshr_b32 flat_scratch_hi, s4, 8
; CIVI-NEXT:    s_add_u32 s0, s0, s7
; CIVI-NEXT:    s_addc_u32 s1, s1, 0
; CIVI-NEXT:    s_mov_b32 s12, s6
; CIVI-NEXT:    v_mov_b32_e32 v0, 0x22b
; CIVI-NEXT:    s_mov_b32 s32, 0
; CIVI-NEXT:    s_mov_b32 flat_scratch_lo, s5
; CIVI-NEXT:    s_getpc_b64 s[4:5]
; CIVI-NEXT:    s_add_u32 s4, s4, other_arg_use_workgroup_id_x@rel32@lo+4
; CIVI-NEXT:    s_addc_u32 s5, s5, other_arg_use_workgroup_id_x@rel32@hi+12
; CIVI-NEXT:    s_swappc_b64 s[30:31], s[4:5]
; CIVI-NEXT:    s_endpgm
;
; GFX9-LABEL: kern_indirect_other_arg_use_workgroup_id_x:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_add_u32 flat_scratch_lo, s4, s7
; GFX9-NEXT:    s_addc_u32 flat_scratch_hi, s5, 0
; GFX9-NEXT:    s_add_u32 s0, s0, s7
; GFX9-NEXT:    s_addc_u32 s1, s1, 0
; GFX9-NEXT:    s_mov_b32 s12, s6
; GFX9-NEXT:    v_mov_b32_e32 v0, 0x22b
; GFX9-NEXT:    s_mov_b32 s32, 0
; GFX9-NEXT:    s_getpc_b64 s[4:5]
; GFX9-NEXT:    s_add_u32 s4, s4, other_arg_use_workgroup_id_x@rel32@lo+4
; GFX9-NEXT:    s_addc_u32 s5, s5, other_arg_use_workgroup_id_x@rel32@hi+12
; GFX9-NEXT:    s_swappc_b64 s[30:31], s[4:5]
; GFX9-NEXT:    s_endpgm
  call void @other_arg_use_workgroup_id_x(i32 555)
  ret void
}

; GCN-LABEL: {{^}}kern_indirect_other_arg_use_workgroup_id_y:
; GCN-DAG: v_mov_b32_e32 v0, 0x22b
; GCN-DAG: s_mov_b32 s13, s7

; GCN-DAG: s_mov_b32 s32, 0
; GCN: s_swappc_b64

; GCN: .amdhsa_system_sgpr_workgroup_id_x 1
; GCN: .amdhsa_system_sgpr_workgroup_id_y 1
; GCN: .amdhsa_system_sgpr_workgroup_id_z 0
define amdgpu_kernel void @kern_indirect_other_arg_use_workgroup_id_y() #1 {
; CIVI-LABEL: kern_indirect_other_arg_use_workgroup_id_y:
; CIVI:       ; %bb.0:
; CIVI-NEXT:    s_add_i32 s4, s4, s8
; CIVI-NEXT:    s_lshr_b32 flat_scratch_hi, s4, 8
; CIVI-NEXT:    s_add_u32 s0, s0, s8
; CIVI-NEXT:    s_addc_u32 s1, s1, 0
; CIVI-NEXT:    s_mov_b32 s13, s7
; CIVI-NEXT:    v_mov_b32_e32 v0, 0x22b
; CIVI-NEXT:    s_mov_b32 s32, 0
; CIVI-NEXT:    s_mov_b32 flat_scratch_lo, s5
; CIVI-NEXT:    s_getpc_b64 s[4:5]
; CIVI-NEXT:    s_add_u32 s4, s4, other_arg_use_workgroup_id_y@rel32@lo+4
; CIVI-NEXT:    s_addc_u32 s5, s5, other_arg_use_workgroup_id_y@rel32@hi+12
; CIVI-NEXT:    s_swappc_b64 s[30:31], s[4:5]
; CIVI-NEXT:    s_endpgm
;
; GFX9-LABEL: kern_indirect_other_arg_use_workgroup_id_y:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_add_u32 flat_scratch_lo, s4, s8
; GFX9-NEXT:    s_addc_u32 flat_scratch_hi, s5, 0
; GFX9-NEXT:    s_add_u32 s0, s0, s8
; GFX9-NEXT:    s_addc_u32 s1, s1, 0
; GFX9-NEXT:    s_mov_b32 s13, s7
; GFX9-NEXT:    v_mov_b32_e32 v0, 0x22b
; GFX9-NEXT:    s_mov_b32 s32, 0
; GFX9-NEXT:    s_getpc_b64 s[4:5]
; GFX9-NEXT:    s_add_u32 s4, s4, other_arg_use_workgroup_id_y@rel32@lo+4
; GFX9-NEXT:    s_addc_u32 s5, s5, other_arg_use_workgroup_id_y@rel32@hi+12
; GFX9-NEXT:    s_swappc_b64 s[30:31], s[4:5]
; GFX9-NEXT:    s_endpgm
  call void @other_arg_use_workgroup_id_y(i32 555)
  ret void
}

; GCN-LABEL: {{^}}kern_indirect_other_arg_use_workgroup_id_z:
; GCN-DAG: v_mov_b32_e32 v0, 0x22b
; GCN-DAG: s_mov_b32 s14, s7

; GCN: s_mov_b32 s32, 0
; GCN: s_swappc_b64

; GCN: .amdhsa_system_sgpr_workgroup_id_x 1
; GCN: .amdhsa_system_sgpr_workgroup_id_y 0
; GCN: .amdhsa_system_sgpr_workgroup_id_z 1
define amdgpu_kernel void @kern_indirect_other_arg_use_workgroup_id_z() #1 {
; CIVI-LABEL: kern_indirect_other_arg_use_workgroup_id_z:
; CIVI:       ; %bb.0:
; CIVI-NEXT:    s_add_i32 s4, s4, s8
; CIVI-NEXT:    s_lshr_b32 flat_scratch_hi, s4, 8
; CIVI-NEXT:    s_add_u32 s0, s0, s8
; CIVI-NEXT:    s_addc_u32 s1, s1, 0
; CIVI-NEXT:    s_mov_b32 s14, s7
; CIVI-NEXT:    v_mov_b32_e32 v0, 0x22b
; CIVI-NEXT:    s_mov_b32 s32, 0
; CIVI-NEXT:    s_mov_b32 flat_scratch_lo, s5
; CIVI-NEXT:    s_getpc_b64 s[4:5]
; CIVI-NEXT:    s_add_u32 s4, s4, other_arg_use_workgroup_id_z@rel32@lo+4
; CIVI-NEXT:    s_addc_u32 s5, s5, other_arg_use_workgroup_id_z@rel32@hi+12
; CIVI-NEXT:    s_swappc_b64 s[30:31], s[4:5]
; CIVI-NEXT:    s_endpgm
;
; GFX9-LABEL: kern_indirect_other_arg_use_workgroup_id_z:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_add_u32 flat_scratch_lo, s4, s8
; GFX9-NEXT:    s_addc_u32 flat_scratch_hi, s5, 0
; GFX9-NEXT:    s_add_u32 s0, s0, s8
; GFX9-NEXT:    s_addc_u32 s1, s1, 0
; GFX9-NEXT:    s_mov_b32 s14, s7
; GFX9-NEXT:    v_mov_b32_e32 v0, 0x22b
; GFX9-NEXT:    s_mov_b32 s32, 0
; GFX9-NEXT:    s_getpc_b64 s[4:5]
; GFX9-NEXT:    s_add_u32 s4, s4, other_arg_use_workgroup_id_z@rel32@lo+4
; GFX9-NEXT:    s_addc_u32 s5, s5, other_arg_use_workgroup_id_z@rel32@hi+12
; GFX9-NEXT:    s_swappc_b64 s[30:31], s[4:5]
; GFX9-NEXT:    s_endpgm
  call void @other_arg_use_workgroup_id_z(i32 555)
  ret void
}

; GCN-LABEL: {{^}}use_every_sgpr_input:
; GCN: buffer_store_dword v{{[0-9]+}}, off, s[0:3], s32{{$}}
; GCN: s_load_dword s{{[0-9]+}}, s[4:5]
; GCN: s_load_dword s{{[0-9]+}}, s[6:7]
; GCN: s_load_dword s{{[0-9]+}}, s[8:9]
; GCN: ; use s[10:11]
; GCN: ; use s12
; GCN: ; use s13
; GCN: ; use s14
define hidden void @use_every_sgpr_input() #1 {
; CIVI-LABEL: use_every_sgpr_input:
; CIVI:       ; %bb.0:
; CIVI-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CIVI-NEXT:    v_mov_b32_e32 v0, 0
; CIVI-NEXT:    buffer_store_dword v0, off, s[0:3], s32
; CIVI-NEXT:    s_waitcnt vmcnt(0)
; CIVI-NEXT:    s_load_dword s4, s[4:5], 0x0
; CIVI-NEXT:    s_waitcnt lgkmcnt(0)
; CIVI-NEXT:    s_load_dword s4, s[6:7], 0x0
; CIVI-NEXT:    s_waitcnt lgkmcnt(0)
; CIVI-NEXT:    s_load_dword s4, s[8:9], 0x0
; CIVI-NEXT:    ;;#ASMSTART
; CIVI-NEXT:    ; use s[10:11]
; CIVI-NEXT:    ;;#ASMEND
; CIVI-NEXT:    ;;#ASMSTART
; CIVI-NEXT:    ; use s12
; CIVI-NEXT:    ;;#ASMEND
; CIVI-NEXT:    ;;#ASMSTART
; CIVI-NEXT:    ; use s13
; CIVI-NEXT:    ;;#ASMEND
; CIVI-NEXT:    ;;#ASMSTART
; CIVI-NEXT:    ; use s14
; CIVI-NEXT:    ;;#ASMEND
; CIVI-NEXT:    s_waitcnt lgkmcnt(0)
; CIVI-NEXT:    s_setpc_b64 s[30:31]
;
; GFX9-LABEL: use_every_sgpr_input:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GFX9-NEXT:    v_mov_b32_e32 v0, 0
; GFX9-NEXT:    buffer_store_dword v0, off, s[0:3], s32
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    s_load_dword s15, s[4:5], 0x0
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    s_load_dword s15, s[6:7], 0x0
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    s_load_dword s15, s[8:9], 0x0
; GFX9-NEXT:    ; kill: killed $sgpr6_sgpr7
; GFX9-NEXT:    ; kill: killed $sgpr8_sgpr9
; GFX9-NEXT:    ; kill: killed $sgpr4_sgpr5
; GFX9-NEXT:    ;;#ASMSTART
; GFX9-NEXT:    ; use s[10:11]
; GFX9-NEXT:    ;;#ASMEND
; GFX9-NEXT:    ;;#ASMSTART
; GFX9-NEXT:    ; use s12
; GFX9-NEXT:    ;;#ASMEND
; GFX9-NEXT:    ;;#ASMSTART
; GFX9-NEXT:    ; use s13
; GFX9-NEXT:    ;;#ASMEND
; GFX9-NEXT:    ;;#ASMSTART
; GFX9-NEXT:    ; use s14
; GFX9-NEXT:    ;;#ASMEND
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    s_setpc_b64 s[30:31]
  %alloca = alloca i32, align 4, addrspace(5)
  store volatile i32 0, ptr addrspace(5) %alloca

  %dispatch_ptr = call noalias ptr addrspace(4) @llvm.amdgcn.dispatch.ptr() #0
  %val0 = load volatile i32, ptr addrspace(4) %dispatch_ptr

  %queue_ptr = call noalias ptr addrspace(4) @llvm.amdgcn.queue.ptr() #0
  %val1 = load volatile i32, ptr addrspace(4) %queue_ptr

  %implicitarg.ptr = call noalias ptr addrspace(4) @llvm.amdgcn.implicitarg.ptr() #0
  %val2 = load volatile i32, ptr addrspace(4) %implicitarg.ptr

  %val3 = call i64 @llvm.amdgcn.dispatch.id()
  call void asm sideeffect "; use $0", "s"(i64 %val3)

  %val4 = call i32 @llvm.amdgcn.workgroup.id.x()
  call void asm sideeffect "; use $0", "s"(i32 %val4)

  %val5 = call i32 @llvm.amdgcn.workgroup.id.y()
  call void asm sideeffect "; use $0", "s"(i32 %val5)

  %val6 = call i32 @llvm.amdgcn.workgroup.id.z()
  call void asm sideeffect "; use $0", "s"(i32 %val6)

  ret void
}

; GCN-LABEL: {{^}}kern_indirect_use_every_sgpr_input:
; GCN: s_mov_b32 s32, 0
; GCN: s_swappc_b64

; GCN: .amdhsa_user_sgpr_private_segment_buffer 1
; GCN: .amdhsa_user_sgpr_dispatch_ptr 1
; GCN: .amdhsa_user_sgpr_queue_ptr 0
; GCN: .amdhsa_user_sgpr_kernarg_segment_ptr 1
; GCN: .amdhsa_user_sgpr_dispatch_id 1
; GCN: .amdhsa_user_sgpr_flat_scratch_init 1
; GCN: .amdhsa_user_sgpr_private_segment_size 0
; GCN: .amdhsa_system_sgpr_private_segment_wavefront_offset 1
; GCN: .amdhsa_system_sgpr_workgroup_id_x 1
; GCN: .amdhsa_system_sgpr_workgroup_id_y 1
; GCN: .amdhsa_system_sgpr_workgroup_id_z 1
; GCN: .amdhsa_system_sgpr_workgroup_info 0
; GCN: .amdhsa_system_vgpr_workitem_id 0
define amdgpu_kernel void @kern_indirect_use_every_sgpr_input(i8) #1 {
; CIVI-LABEL: kern_indirect_use_every_sgpr_input:
; CIVI:       ; %bb.0:
; CIVI-NEXT:    s_add_i32 s12, s12, s17
; CIVI-NEXT:    s_lshr_b32 flat_scratch_hi, s12, 8
; CIVI-NEXT:    s_add_u32 s0, s0, s17
; CIVI-NEXT:    s_addc_u32 s1, s1, 0
; CIVI-NEXT:    s_add_u32 s8, s8, 8
; CIVI-NEXT:    s_mov_b32 flat_scratch_lo, s13
; CIVI-NEXT:    s_mov_b32 s13, s15
; CIVI-NEXT:    s_mov_b32 s12, s14
; CIVI-NEXT:    s_addc_u32 s9, s9, 0
; CIVI-NEXT:    s_mov_b32 s14, s16
; CIVI-NEXT:    s_mov_b32 s32, 0
; CIVI-NEXT:    s_getpc_b64 s[18:19]
; CIVI-NEXT:    s_add_u32 s18, s18, use_every_sgpr_input@rel32@lo+4
; CIVI-NEXT:    s_addc_u32 s19, s19, use_every_sgpr_input@rel32@hi+12
; CIVI-NEXT:    s_swappc_b64 s[30:31], s[18:19]
; CIVI-NEXT:    s_endpgm
;
; GFX9-LABEL: kern_indirect_use_every_sgpr_input:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_add_u32 flat_scratch_lo, s12, s17
; GFX9-NEXT:    s_addc_u32 flat_scratch_hi, s13, 0
; GFX9-NEXT:    s_add_u32 s0, s0, s17
; GFX9-NEXT:    s_addc_u32 s1, s1, 0
; GFX9-NEXT:    s_add_u32 s8, s8, 8
; GFX9-NEXT:    s_mov_b32 s13, s15
; GFX9-NEXT:    s_mov_b32 s12, s14
; GFX9-NEXT:    s_addc_u32 s9, s9, 0
; GFX9-NEXT:    s_mov_b32 s14, s16
; GFX9-NEXT:    s_mov_b32 s32, 0
; GFX9-NEXT:    s_getpc_b64 s[18:19]
; GFX9-NEXT:    s_add_u32 s18, s18, use_every_sgpr_input@rel32@lo+4
; GFX9-NEXT:    s_addc_u32 s19, s19, use_every_sgpr_input@rel32@hi+12
; GFX9-NEXT:    s_swappc_b64 s[30:31], s[18:19]
; GFX9-NEXT:    s_endpgm
  call void @use_every_sgpr_input()
  ret void
}

; We have to pass the kernarg segment, but there are no kernel
; arguments so null is passed.
; GCN-LABEL: {{^}}kern_indirect_use_every_sgpr_input_no_kernargs:
; GCN: s_mov_b64 s[10:11], s[6:7]
; GCN: s_mov_b32 s32, 0
; GCN: s_swappc_b64

; GCN: .amdhsa_user_sgpr_private_segment_buffer 1
; GCN: .amdhsa_user_sgpr_dispatch_ptr 1
; GCN: .amdhsa_user_sgpr_queue_ptr 0
; GCN: .amdhsa_user_sgpr_kernarg_segment_ptr 0
; GCN: .amdhsa_user_sgpr_dispatch_id 1
; GCN: .amdhsa_user_sgpr_flat_scratch_init 1
; GCN: .amdhsa_user_sgpr_private_segment_size 0
; GCN: .amdhsa_system_sgpr_private_segment_wavefront_offset 1
; GCN: .amdhsa_system_sgpr_workgroup_id_x 1
; GCN: .amdhsa_system_sgpr_workgroup_id_y 1
; GCN: .amdhsa_system_sgpr_workgroup_id_z 1
; GCN: .amdhsa_system_sgpr_workgroup_info 0
; GCN: .amdhsa_system_vgpr_workitem_id 0
define amdgpu_kernel void @kern_indirect_use_every_sgpr_input_no_kernargs() #2 {
; CIVI-LABEL: kern_indirect_use_every_sgpr_input_no_kernargs:
; CIVI:       ; %bb.0:
; CIVI-NEXT:    s_add_i32 s10, s10, s15
; CIVI-NEXT:    s_lshr_b32 flat_scratch_hi, s10, 8
; CIVI-NEXT:    s_add_u32 s0, s0, s15
; CIVI-NEXT:    s_mov_b32 flat_scratch_lo, s11
; CIVI-NEXT:    s_addc_u32 s1, s1, 0
; CIVI-NEXT:    s_mov_b64 s[10:11], s[8:9]
; CIVI-NEXT:    s_mov_b64 s[8:9], 0
; CIVI-NEXT:    s_mov_b32 s32, 0
; CIVI-NEXT:    s_getpc_b64 s[16:17]
; CIVI-NEXT:    s_add_u32 s16, s16, use_every_sgpr_input@rel32@lo+4
; CIVI-NEXT:    s_addc_u32 s17, s17, use_every_sgpr_input@rel32@hi+12
; CIVI-NEXT:    s_swappc_b64 s[30:31], s[16:17]
; CIVI-NEXT:    s_endpgm
;
; GFX9-LABEL: kern_indirect_use_every_sgpr_input_no_kernargs:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_add_u32 flat_scratch_lo, s10, s15
; GFX9-NEXT:    s_addc_u32 flat_scratch_hi, s11, 0
; GFX9-NEXT:    s_add_u32 s0, s0, s15
; GFX9-NEXT:    s_addc_u32 s1, s1, 0
; GFX9-NEXT:    s_mov_b64 s[10:11], s[8:9]
; GFX9-NEXT:    s_mov_b64 s[8:9], 0
; GFX9-NEXT:    s_mov_b32 s32, 0
; GFX9-NEXT:    s_getpc_b64 s[16:17]
; GFX9-NEXT:    s_add_u32 s16, s16, use_every_sgpr_input@rel32@lo+4
; GFX9-NEXT:    s_addc_u32 s17, s17, use_every_sgpr_input@rel32@hi+12
; GFX9-NEXT:    s_swappc_b64 s[30:31], s[16:17]
; GFX9-NEXT:    s_endpgm
  call void @use_every_sgpr_input()
  ret void
}

; GCN-LABEL: {{^}}func_indirect_use_every_sgpr_input:
; GCN-NOT: s6
; GCN-NOT: s7
; GCN-NOT: s8
; GCN-NOT: s9
; GCN-NOT: s10
; GCN-NOT: s11
; GCN-NOT: s12
; GCN-NOT: s13
; GCN-NOT: s[6:7]
; GCN-NOT: s[8:9]
; GCN-NOT: s[10:11]
; GCN-NOT: s[12:13]
; GCN-NOT: s14
; GCN: s_or_saveexec_b64 s[16:17], -1
define hidden void @func_indirect_use_every_sgpr_input() #1 {
; GCN-LABEL: func_indirect_use_every_sgpr_input:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    s_mov_b32 s15, s33
; GCN-NEXT:    s_mov_b32 s33, s32
; GCN-NEXT:    s_or_saveexec_b64 s[16:17], -1
; GCN-NEXT:    buffer_store_dword v40, off, s[0:3], s33 ; 4-byte Folded Spill
; GCN-NEXT:    s_mov_b64 exec, s[16:17]
; GCN-NEXT:    v_writelane_b32 v40, s15, 2
; GCN-NEXT:    s_addk_i32 s32, 0x400
; GCN-NEXT:    v_writelane_b32 v40, s30, 0
; GCN-NEXT:    v_writelane_b32 v40, s31, 1
; GCN-NEXT:    s_getpc_b64 s[16:17]
; GCN-NEXT:    s_add_u32 s16, s16, use_every_sgpr_input@rel32@lo+4
; GCN-NEXT:    s_addc_u32 s17, s17, use_every_sgpr_input@rel32@hi+12
; GCN-NEXT:    s_swappc_b64 s[30:31], s[16:17]
; GCN-NEXT:    v_readlane_b32 s31, v40, 1
; GCN-NEXT:    v_readlane_b32 s30, v40, 0
; GCN-NEXT:    v_readlane_b32 s4, v40, 2
; GCN-NEXT:    s_or_saveexec_b64 s[6:7], -1
; GCN-NEXT:    buffer_load_dword v40, off, s[0:3], s33 ; 4-byte Folded Reload
; GCN-NEXT:    s_mov_b64 exec, s[6:7]
; GCN-NEXT:    s_addk_i32 s32, 0xfc00
; GCN-NEXT:    s_mov_b32 s33, s4
; GCN-NEXT:    s_waitcnt vmcnt(0)
; GCN-NEXT:    s_setpc_b64 s[30:31]
  call void @use_every_sgpr_input()
  ret void
}

; GCN-LABEL: {{^}}func_use_every_sgpr_input_call_use_workgroup_id_xyz:
; GCN-NOT: s12
; GCN-NOT: s13
; GCN-NOT: s14
; GCN: ; use s[10:11]
; GCN: ; use s12
; GCN: ; use s13
; GCN: ; use s14

; GCN: s_swappc_b64
define hidden void @func_use_every_sgpr_input_call_use_workgroup_id_xyz() #1 {
; CIVI-LABEL: func_use_every_sgpr_input_call_use_workgroup_id_xyz:
; CIVI:       ; %bb.0:
; CIVI-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CIVI-NEXT:    s_mov_b32 s15, s33
; CIVI-NEXT:    s_mov_b32 s33, s32
; CIVI-NEXT:    s_or_saveexec_b64 s[16:17], -1
; CIVI-NEXT:    buffer_store_dword v40, off, s[0:3], s33 offset:4 ; 4-byte Folded Spill
; CIVI-NEXT:    s_mov_b64 exec, s[16:17]
; CIVI-NEXT:    v_mov_b32_e32 v0, 0
; CIVI-NEXT:    buffer_store_dword v0, off, s[0:3], s33
; CIVI-NEXT:    s_waitcnt vmcnt(0)
; CIVI-NEXT:    s_load_dword s4, s[4:5], 0x0
; CIVI-NEXT:    s_waitcnt lgkmcnt(0)
; CIVI-NEXT:    s_load_dword s4, s[6:7], 0x0
; CIVI-NEXT:    s_waitcnt lgkmcnt(0)
; CIVI-NEXT:    s_load_dword s4, s[8:9], 0x0
; CIVI-NEXT:    v_writelane_b32 v40, s15, 2
; CIVI-NEXT:    s_addk_i32 s32, 0x400
; CIVI-NEXT:    v_writelane_b32 v40, s30, 0
; CIVI-NEXT:    v_writelane_b32 v40, s31, 1
; CIVI-NEXT:    ;;#ASMSTART
; CIVI-NEXT:    ; use s[10:11]
; CIVI-NEXT:    ;;#ASMEND
; CIVI-NEXT:    ;;#ASMSTART
; CIVI-NEXT:    ; use s12
; CIVI-NEXT:    ;;#ASMEND
; CIVI-NEXT:    ;;#ASMSTART
; CIVI-NEXT:    ; use s13
; CIVI-NEXT:    ;;#ASMEND
; CIVI-NEXT:    ;;#ASMSTART
; CIVI-NEXT:    ; use s14
; CIVI-NEXT:    ;;#ASMEND
; CIVI-NEXT:    s_waitcnt lgkmcnt(0)
; CIVI-NEXT:    s_getpc_b64 s[4:5]
; CIVI-NEXT:    s_add_u32 s4, s4, use_workgroup_id_xyz@rel32@lo+4
; CIVI-NEXT:    s_addc_u32 s5, s5, use_workgroup_id_xyz@rel32@hi+12
; CIVI-NEXT:    s_swappc_b64 s[30:31], s[4:5]
; CIVI-NEXT:    v_readlane_b32 s31, v40, 1
; CIVI-NEXT:    v_readlane_b32 s30, v40, 0
; CIVI-NEXT:    v_readlane_b32 s4, v40, 2
; CIVI-NEXT:    s_or_saveexec_b64 s[6:7], -1
; CIVI-NEXT:    buffer_load_dword v40, off, s[0:3], s33 offset:4 ; 4-byte Folded Reload
; CIVI-NEXT:    s_mov_b64 exec, s[6:7]
; CIVI-NEXT:    s_addk_i32 s32, 0xfc00
; CIVI-NEXT:    s_mov_b32 s33, s4
; CIVI-NEXT:    s_waitcnt vmcnt(0)
; CIVI-NEXT:    s_setpc_b64 s[30:31]
;
; GFX9-LABEL: func_use_every_sgpr_input_call_use_workgroup_id_xyz:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GFX9-NEXT:    s_mov_b32 s15, s33
; GFX9-NEXT:    s_mov_b32 s33, s32
; GFX9-NEXT:    s_or_saveexec_b64 s[16:17], -1
; GFX9-NEXT:    buffer_store_dword v40, off, s[0:3], s33 offset:4 ; 4-byte Folded Spill
; GFX9-NEXT:    s_mov_b64 exec, s[16:17]
; GFX9-NEXT:    v_mov_b32_e32 v0, 0
; GFX9-NEXT:    buffer_store_dword v0, off, s[0:3], s33
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_writelane_b32 v40, s15, 2
; GFX9-NEXT:    s_load_dword s15, s[4:5], 0x0
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    s_load_dword s15, s[6:7], 0x0
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    s_load_dword s15, s[8:9], 0x0
; GFX9-NEXT:    s_addk_i32 s32, 0x400
; GFX9-NEXT:    v_writelane_b32 v40, s30, 0
; GFX9-NEXT:    v_writelane_b32 v40, s31, 1
; GFX9-NEXT:    ; kill: killed $sgpr6_sgpr7
; GFX9-NEXT:    ; kill: killed $sgpr8_sgpr9
; GFX9-NEXT:    ; kill: killed $sgpr4_sgpr5
; GFX9-NEXT:    ;;#ASMSTART
; GFX9-NEXT:    ; use s[10:11]
; GFX9-NEXT:    ;;#ASMEND
; GFX9-NEXT:    ;;#ASMSTART
; GFX9-NEXT:    ; use s12
; GFX9-NEXT:    ;;#ASMEND
; GFX9-NEXT:    ;;#ASMSTART
; GFX9-NEXT:    ; use s13
; GFX9-NEXT:    ;;#ASMEND
; GFX9-NEXT:    ;;#ASMSTART
; GFX9-NEXT:    ; use s14
; GFX9-NEXT:    ;;#ASMEND
; GFX9-NEXT:    s_getpc_b64 s[4:5]
; GFX9-NEXT:    s_add_u32 s4, s4, use_workgroup_id_xyz@rel32@lo+4
; GFX9-NEXT:    s_addc_u32 s5, s5, use_workgroup_id_xyz@rel32@hi+12
; GFX9-NEXT:    s_swappc_b64 s[30:31], s[4:5]
; GFX9-NEXT:    v_readlane_b32 s31, v40, 1
; GFX9-NEXT:    v_readlane_b32 s30, v40, 0
; GFX9-NEXT:    v_readlane_b32 s4, v40, 2
; GFX9-NEXT:    s_or_saveexec_b64 s[6:7], -1
; GFX9-NEXT:    buffer_load_dword v40, off, s[0:3], s33 offset:4 ; 4-byte Folded Reload
; GFX9-NEXT:    s_mov_b64 exec, s[6:7]
; GFX9-NEXT:    s_addk_i32 s32, 0xfc00
; GFX9-NEXT:    s_mov_b32 s33, s4
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    s_setpc_b64 s[30:31]
  %alloca = alloca i32, align 4, addrspace(5)
  store volatile i32 0, ptr addrspace(5) %alloca

  %dispatch_ptr = call noalias ptr addrspace(4) @llvm.amdgcn.dispatch.ptr() #0
  %val0 = load volatile i32, ptr addrspace(4) %dispatch_ptr

  %queue_ptr = call noalias ptr addrspace(4) @llvm.amdgcn.queue.ptr() #0
  %val1 = load volatile i32, ptr addrspace(4) %queue_ptr

  %kernarg_segment_ptr = call noalias ptr addrspace(4) @llvm.amdgcn.implicitarg.ptr() #0
  %val2 = load volatile i32, ptr addrspace(4) %kernarg_segment_ptr

  %val3 = call i64 @llvm.amdgcn.dispatch.id()
  call void asm sideeffect "; use $0", "s"(i64 %val3)

  %val4 = call i32 @llvm.amdgcn.workgroup.id.x()
  call void asm sideeffect "; use $0", "s"(i32 %val4)

  %val5 = call i32 @llvm.amdgcn.workgroup.id.y()
  call void asm sideeffect "; use $0", "s"(i32 %val5)

  %val6 = call i32 @llvm.amdgcn.workgroup.id.z()
  call void asm sideeffect "; use $0", "s"(i32 %val6)

  call void @use_workgroup_id_xyz()
  ret void
}

declare i32 @llvm.amdgcn.workgroup.id.x() #0
declare i32 @llvm.amdgcn.workgroup.id.y() #0
declare i32 @llvm.amdgcn.workgroup.id.z() #0
declare noalias ptr addrspace(4) @llvm.amdgcn.queue.ptr() #0
declare noalias ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr() #0
declare noalias ptr addrspace(4) @llvm.amdgcn.implicitarg.ptr() #0
declare i64 @llvm.amdgcn.dispatch.id() #0
declare noalias ptr addrspace(4) @llvm.amdgcn.dispatch.ptr() #0

attributes #0 = { nounwind readnone speculatable }
attributes #1 = { nounwind noinline }
attributes #2 = { nounwind noinline "amdgpu-implicitarg-num-bytes"="0" }

!llvm.module.flags = !{!0}
!0 = !{i32 1, !"amdhsa_code_object_version", i32 500}
